{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 1s 24us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 32s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 4s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"matplotlib\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/c0/69e3f695d7384012e90be1e16570c08953baae00fd98094179ef87c7d5a2/matplotlib-3.1.1-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from matplotlib) (2.8.0)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/11/fa/0160cd525c62d7abd076a070ff02b2b94de589f1a9789774f17d7c54058e/pyparsing-2.4.2-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/c6/ea/e5474014a13ab2dcb5056608e0716c600c3d8a8bcffb10ed55ccd6a42eb0/kiwisolver-1.1.0-cp37-none-win_amd64.whl\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from matplotlib) (1.16.5)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n",
      "Installing collected packages: pyparsing, kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.1.0 matplotlib-3.1.1 pyparsing-2.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0  51   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 139 214 218 220 164 206 243 233 205\n",
      "   93   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 130 253 225 226 233 229 232 230 219 227\n",
      "  249  63   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 203 237 221 222 221 222 219 220 224 218\n",
      "  233 191   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 232 237 224 225 224 224 222 221 225 218\n",
      "  224 253   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 255 232 223 225 222 221 219 216 219 212\n",
      "  223 255  30   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   5 255 230 224 221 223 218 219 217 221 214\n",
      "  229 255  89   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  32 255 228 221 220 223 221 221 218 217 221\n",
      "  232 255 113   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  78 255 227 218 220 221 226 225 219 215 232\n",
      "  168 255 148   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 115 255 237 221 221 218 228 227 219 216 241\n",
      "  107 255 152   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 144 255 218 223 220 215 223 222 215 216 240\n",
      "  119 255 154   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 167 255 102 224 223 215 219 220 213 213 234\n",
      "  131 255 165   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 170 255  34 221 229 215 217 217 214 216 238\n",
      "  102 254 175   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 172 255  27 235 225 215 214 215 215 213 246\n",
      "  104 253 181   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 173 255  18 249 217 215 215 215 216 210 241\n",
      "   95 247 183   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 172 255  19 252 214 216 215 214 215 211 245\n",
      "  106 244 176   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 164 254  27 253 212 217 216 214 215 214 243\n",
      "  110 243 145   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 169 255  42 253 211 215 218 218 215 215 233\n",
      "  149 255 141   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 103 131  49 253 212 216 222 219 217 214 249\n",
      "  128 122  78   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  58 254 218 217 225 218 219 212 253\n",
      "  110   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   4   0  64 237 219 220 229 217 222 217 235\n",
      "  129   0   3   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   3   0  54 239 221 222 231 215 225 217 237\n",
      "  125   0   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   3   0  50 241 220 224 233 212 227 217 241\n",
      "  120   0   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   3   0  41 242 222 226 236 213 228 220 243\n",
      "  113   0   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   3   0  33 242 224 228 239 216 230 221 245\n",
      "   97   0   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   3   0  13 237 224 226 235 208 226 218 246\n",
      "   65   0   3   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0 217 244 245 255 253 241 236 248\n",
      "   22   0   1   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 115 181 103  54 141 146 134 101\n",
      "    0   0   1   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(training_images[25])\n",
    "print(training_labels[25])\n",
    "print(training_images[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.2788 - acc: 0.8965\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2649 - acc: 0.9018\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.2566 - acc: 0.9049\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2454 - acc: 0.9084\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2346 - acc: 0.9125\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2288 - acc: 0.9143\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2195 - acc: 0.9178\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2155 - acc: 0.9194\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2053 - acc: 0.9227\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2022 - acc: 0.9233\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.1950 - acc: 0.9271\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.1903 - acc: 0.9283\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1880 - acc: 0.9299\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.1803 - acc: 0.9333\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1742 - acc: 0.9347\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1709 - acc: 0.9357\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1677 - acc: 0.9366\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1634 - acc: 0.9390\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1608 - acc: 0.9396\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1569 - acc: 0.9415\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1511 - acc: 0.9437\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1479 - acc: 0.9438\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1457 - acc: 0.9453\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.1426 - acc: 0.9462\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.1411 - acc: 0.9476\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1370 - acc: 0.9472\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1326 - acc: 0.9502\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1312 - acc: 0.9508\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1269 - acc: 0.9530\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1267 - acc: 0.9521\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.1234 - acc: 0.9540\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1199 - acc: 0.9550\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.1187 - acc: 0.9552\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.1155 - acc: 0.9570\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1168 - acc: 0.9570\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.1114 - acc: 0.9586\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.1115 - acc: 0.9576\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.1097 - acc: 0.9598\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.1063 - acc: 0.9596\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.1055 - acc: 0.9597\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.1055 - acc: 0.9605\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.1028 - acc: 0.9617\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0997 - acc: 0.9631\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0993 - acc: 0.9631\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0960 - acc: 0.9640\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0954 - acc: 0.9645\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0954 - acc: 0.9637\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0926 - acc: 0.9645\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0893 - acc: 0.9669\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0880 - acc: 0.9667\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0893 - acc: 0.9663\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0866 - acc: 0.9679\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0867 - acc: 0.9681\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0849 - acc: 0.9683\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0822 - acc: 0.9692\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0811 - acc: 0.9693\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0806 - acc: 0.9700\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0823 - acc: 0.9693\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.0764 - acc: 0.9714\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0782 - acc: 0.9708\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0783 - acc: 0.9709\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0753 - acc: 0.9718\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0773 - acc: 0.9712\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0747 - acc: 0.9716\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0718 - acc: 0.9726\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0722 - acc: 0.9723\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0714 - acc: 0.9730\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0697 - acc: 0.9740\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0669 - acc: 0.9760\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0704 - acc: 0.9736\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0678 - acc: 0.9749\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0682 - acc: 0.9744\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0652 - acc: 0.9754\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0652 - acc: 0.9764\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0650 - acc: 0.9756\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0637 - acc: 0.9755\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0621 - acc: 0.9765\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0629 - acc: 0.9757\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0610 - acc: 0.9779\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0607 - acc: 0.9777\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0629 - acc: 0.9764\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0608 - acc: 0.9776\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0572 - acc: 0.9788\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0627 - acc: 0.9768\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0568 - acc: 0.9791\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0562 - acc: 0.9790\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0574 - acc: 0.9792\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0571 - acc: 0.9786\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0561 - acc: 0.9786\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0548 - acc: 0.9793\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0534 - acc: 0.9798\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0536 - acc: 0.9798\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0544 - acc: 0.9796\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0530 - acc: 0.9803\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0524 - acc: 0.9803\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0510 - acc: 0.9808\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0510 - acc: 0.9811\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0529 - acc: 0.9806\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0509 - acc: 0.9811\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0499 - acc: 0.9816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2620d85b748>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.7971 - acc: 0.8812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7971116393305361, 0.8812]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.2092235e-20 3.0937795e-32 1.1085749e-18 5.0421067e-31 2.0179704e-28\n",
      " 7.8797850e-11 5.8753397e-14 5.3809851e-10 4.7034510e-25 1.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1830\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0739\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0469\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0334\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0258\n",
      "10000/10000 [==============================] - 0s 42us/sample - loss: 0.0619\n",
      "[1.3887804e-07 3.8143558e-10 1.5957459e-08 3.5216722e-06 1.0433183e-13\n",
      " 2.2617160e-10 3.0141478e-14 9.9999356e-01 1.9189371e-10 2.7670278e-06]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.4759 - acc: 0.8303\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3608 - acc: 0.8702\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3215 - acc: 0.8816\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2969 - acc: 0.8893\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2787 - acc: 0.8973\n",
      "Epoch 6/10\n",
      "59936/60000 [============================>.] - ETA: 0s - loss: 0.2628 - acc: 0.9023\n",
      "Reached 60% accuracy so cancelling training!\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2627 - acc: 0.9023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26129430c88>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.9):\n",
    "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
